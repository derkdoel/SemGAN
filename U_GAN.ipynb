{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "H0nYlSqvlHin"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uNqpqVs9g3kA"
      },
      "source": [
        "#Import cityscapes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kJyZR9Q351CE"
      },
      "outputs": [],
      "source": [
        "! mkdir /content/cityScapes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gkYja-9MWqdX"
      },
      "outputs": [],
      "source": [
        "! wget --keep-session-cookies --save-cookies=cookies.txt --post-data 'username=d.a.vandendoel@students.uu.nl&password=Derkojo95!&submit=Login' https://www.cityscapes-dataset.com/login/\n",
        "! wget --load-cookies cookies.txt --content-disposition https://www.cityscapes-dataset.com/file-handling/?packageID=1 -P /content/cityScapes\n",
        "! wget --load-cookies cookies.txt --content-disposition https://www.cityscapes-dataset.com/file-handling/?packageID=3 -P /content/cityScapes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Ps2MJcC6K49"
      },
      "outputs": [],
      "source": [
        "! unzip /content/cityScapes/gtFine_trainvaltest.zip -d /content/cityScapes/annotations\n",
        "! unzip /content/cityScapes/leftImg8bit_trainvaltest.zip -d /content/cityScapes/img"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oGT_vwW0hJRK"
      },
      "source": [
        "#Mount drive and import packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "waujOpX8RF0k"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ufsj9SjJsEFT"
      },
      "outputs": [],
      "source": [
        "!pip install tensorflow_addons"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BC3rkgDtoq6V"
      },
      "outputs": [],
      "source": [
        "!python -m pip install cityscapesscripts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bIJTdDilt6-Y"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import datetime\n",
        "import itertools\n",
        "import os\n",
        "import PIL\n",
        "import scipy\n",
        "import sys\n",
        "import time\n",
        "import json\n",
        "\n",
        "import numpy as np \n",
        "import pandas as pd \n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow_addons as tfa\n",
        "from tensorflow_addons.layers import SpectralNormalization\n",
        "import matplotlib.pyplot as plt\n",
        "from skimage import transform\n",
        "from tqdm import tqdm\n",
        "from random import randint, seed\n",
        "from google.colab.patches import cv2_imshow\n",
        "from imageio import imread\n",
        "from tensorflow.keras import layers\n",
        "from glob import glob\n",
        "from IPython import display\n",
        "from random import randint\n",
        "from skimage.metrics import structural_similarity as SSIM\n",
        "\n",
        "print(os.listdir(\"../content/\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Qcr2R4c9DMY"
      },
      "source": [
        "# Load image and apply mask"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kbtkLyLDqs4l"
      },
      "outputs": [],
      "source": [
        "IM_HEIGHT = 256\n",
        "IM_WIDTH = 512\n",
        "BUFFER_SIZE = 2975\n",
        "BATCH_SIZE = 1\n",
        "OUTPUT_CHANNELS = 3\n",
        "MASK_HEIGTH = 64\n",
        "MASK_WIDTH = 32"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3Cz4Oiv0JndM"
      },
      "outputs": [],
      "source": [
        "def load(image_file, channels, semantics = False,):\n",
        "  image = tf.io.read_file(image_file)\n",
        "  image = tf.io.decode_png(image, channels = channels)\n",
        "  image = tf.cast(image, tf.float32)\n",
        "\n",
        "  return image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BtY1dgp7aSIn"
      },
      "outputs": [],
      "source": [
        "def resize(input_image, height, width):\n",
        "    image = tf.image.resize(\n",
        "        input_image, \n",
        "        [height, width],\n",
        "        method=tf.image.ResizeMethod.NEAREST_NEIGHBOR\n",
        "    )\n",
        "  \n",
        "    return image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bG5mJYAlBjlK"
      },
      "outputs": [],
      "source": [
        "def normalize(image):\n",
        "  image = image / 127.5 - 1\n",
        "  return image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FVdxoGt_EYj6"
      },
      "outputs": [],
      "source": [
        "def image_mask(image, mask_height, mask_width, num_masks, rand_seed = None):\n",
        "  # random_cutout function needs mask_height * mask_width to be divisible by 2\n",
        "  if (mask_height * mask_width)%2 != 0:\n",
        "    raise Exception(\"Error! mask size must be divisible by 2\")\n",
        "  \n",
        "  im_height = tf.cast(IM_HEIGHT, dtype=tf.dtypes.int32)\n",
        "  im_width = tf.cast(IM_WIDTH, dtype=tf.dtypes.int32)  \n",
        "  mask_height = tf.cast(mask_height, dtype=tf.dtypes.int32)\n",
        "  mask_width = tf.cast(mask_width, dtype=tf.dtypes.int32)\n",
        "  \n",
        "  min_height = tf.cast(tf.math.round((mask_height/2)+15), tf.dtypes.int32)\n",
        "  min_width = tf.cast(tf.math.round((mask_width/2)+10), tf.dtypes.int32)\n",
        "  max_height = tf.cast(tf.math.round(im_height/10), tf.dtypes.int32)\n",
        "\n",
        "  try:\n",
        "    image_shape = image.shape\n",
        "  except:\n",
        "    image_shape = image.get_shape()\n",
        "\n",
        "  if len(image_shape) == 3:\n",
        "    image = tf.expand_dims(image, 0)\n",
        "  elif len(image_shape) == 4:\n",
        "    pass\n",
        "  else:\n",
        "    raise Exception('Error! Tensor shape must either be: (batch_size, image height, image width, color channels) or (image height, image width, color channels)')\n",
        "  \n",
        "  mask = tf.zeros_like(image, tf.dtypes.float32)[:,:,:,0:1]\n",
        "  locations = []\n",
        "\n",
        "  #create masks\n",
        "  for i in range(num_masks):\n",
        "    mask_height_random = tf.random.uniform(shape = (), minval= mask_height-5, maxval=mask_height+15, dtype=tf.dtypes.int32, seed=rand_seed)\n",
        "    mask_height_random = mask_height_random if mask_height_random%2 == 0 else mask_height_random-1\n",
        "    mask_width_random = tf.random.uniform(shape = (), minval= mask_width, maxval=mask_width+10, dtype=tf.dtypes.int32, seed=rand_seed)\n",
        "    mask_width_random = mask_width_random if mask_width_random%2 == 0 else mask_width_random-1\n",
        "    \n",
        "    height_offset = tf.random.uniform(shape = (), minval= min_height, maxval=im_height-max_height, dtype=tf.dtypes.int32, seed=rand_seed)\n",
        "    width_offset = tf.random.uniform(shape = (), minval= min_width, maxval= im_width-min_width, dtype=tf.dtypes.int32, seed=rand_seed)\n",
        "    mask = tfa.image.cutout(mask, (mask_height_random, mask_width_random), (height_offset, width_offset), constant_values = 1)\n",
        "    locations.append((mask_height_random, mask_width_random, height_offset, width_offset))\n",
        "  \n",
        "  masked_image = (1-mask) * image\n",
        "\n",
        "    #mask = tf.zeros([image_heigt, image_width])\n",
        "    #mask = mask[height_offset:height_offset+mask_height].assign(tf.ones([mask_height, mask_width]))\n",
        "    #image = mask * image\n",
        "\n",
        "\n",
        "  return masked_image[0], mask[0], locations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cgw3eWvVsxVH"
      },
      "outputs": [],
      "source": [
        "def load_images(image_file):\n",
        "  image = load(image_file, 3)\n",
        "  image = resize(image, IM_HEIGHT, IM_WIDTH)\n",
        "  masked_image, mask, locations = image_mask(image, 64, 32, 4)\n",
        "  image = normalize(image)\n",
        "  masked_image = normalize(masked_image)\n",
        "\n",
        "  #semantics = tf.io.read_file(semantics_file)\n",
        "  #semantics = tf.io.decode_png(semantics, channels = 0)\n",
        "  #semantics = tf.cast(semantics, tf.int32)\n",
        "  #semantics = resize(semantics, 256, 512)\n",
        "\n",
        "\n",
        "\n",
        "  #masked_image, image, mask, image_file, locations\n",
        "  return masked_image, image, mask, image_file, locations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ULcR49yeeAR"
      },
      "source": [
        "# Data loader pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lTyeIWShgWoO"
      },
      "outputs": [],
      "source": [
        "# Fill pandas dataframe with the paths to the files\n",
        "def folder_to_pd(image_dir, semantics_dir):\n",
        "  image_paths = {\"test\": [], \"train\": [], \"val\": []}\n",
        "  semantics_paths = {\"test\": [], \"train\": [], \"val\": []}\n",
        "  json_paths = {\"test\": [], \"train\": [], \"val\": []}\n",
        "\n",
        "  for data_type in [\"test\", \"train\", \"val\"]:\n",
        "    image_subdir = os.path.join(image_dir, data_type)\n",
        "    for root, subdir, files in os.walk(image_subdir):\n",
        "      subdir.sort()\n",
        "      files.sort()\n",
        "      if files:\n",
        "        for file in files:\n",
        "          image_paths[data_type].append(os.path.join(root, file))\n",
        "\n",
        "  \n",
        "  for data_type in [\"test\", \"train\", \"val\"]:\n",
        "    semantics_subdir = os.path.join(semantics_dir, data_type)\n",
        "    for root, subdir, files in os.walk(semantics_subdir):\n",
        "      subdir.sort()\n",
        "      files.sort()\n",
        "      if files:\n",
        "        for i,file in enumerate(files):\n",
        "          if file[-9:] == \"color.png\":\n",
        "            semantics_paths[data_type].append(os.path.join(root, file))\n",
        "          if file[-12:] == \"labelIds.png\":\n",
        "            json_paths[data_type].append(os.path.join(root, file))\n",
        "\n",
        "\n",
        "  test_ds = pd.DataFrame(list(zip(image_paths[\"test\"], semantics_paths[\"test\"], json_paths[\"test\"])), columns =['Image', 'Semantics', 'label'])\n",
        "  train_ds = pd.DataFrame(list(zip(image_paths[\"train\"], semantics_paths[\"train\"], json_paths[\"train\"])), columns =['Image', 'Semantics', 'label'])\n",
        "  val_ds = pd.DataFrame(list(zip(image_paths[\"val\"], semantics_paths[\"val\"], json_paths[\"val\"])), columns =['Image', 'Semantics', 'label'])\n",
        "\n",
        "  return test_ds, train_ds, val_ds\n",
        "\n",
        "test_pd, train_pd, val_pd = folder_to_pd(\"/content/cityScapes/img/leftImg8bit\", \"/content/cityScapes/annotations/gtFine\")\n",
        "\n",
        "\n",
        "test_ds = tf.data.Dataset.from_tensor_slices((test_pd[\"Image\"], test_pd[\"Semantics\"], test_pd[\"label\"]))\n",
        "train_ds = tf.data.Dataset.from_tensor_slices((train_pd[\"Image\"], train_pd[\"Semantics\"], train_pd[\"label\"]))\n",
        "val_ds = tf.data.Dataset.from_tensor_slices((val_pd[\"Image\"], val_pd[\"Semantics\"], val_pd[\"label\"]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DH7P538eeYWu"
      },
      "outputs": [],
      "source": [
        "tf_train = train_ds.shuffle(train_ds.cardinality(), reshuffle_each_iteration=True)\n",
        "#tf_train = tf_train.interleave(tf.data.TFRecordDataset, num_parallel_calls = tf.data.AUTOTUNE)\n",
        "tf_train = tf_train.map(load_images, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "tf_train = tf_train.batch(BATCH_SIZE)\n",
        "tf_train = tf_train.cache(\"/content/temporary.tfcache\")\n",
        "tf_train = tf_train.prefetch(tf.data.AUTOTUNE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eV1tjmJIjoOR"
      },
      "outputs": [],
      "source": [
        "tf_val = val_ds.map(load_images, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "tf_val = tf_val.batch(BATCH_SIZE)\n",
        "tf_val = tf_val.prefetch(tf.data.AUTOTUNE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Up9HfI1T9iUP"
      },
      "source": [
        "# GAN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rk16v6L49gMr"
      },
      "outputs": [],
      "source": [
        "OUTPUT_CHANNELS = 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OSjvFNEu9wCZ"
      },
      "outputs": [],
      "source": [
        "def downsample(filters, size, apply_batchnorm=True):\n",
        "    initializer = tf.random_normal_initializer(0., 0.02)\n",
        "\n",
        "    result = tf.keras.Sequential()\n",
        "    result.add(\n",
        "        tf.keras.layers.Conv2D(filters, size, strides=2, padding='same',\n",
        "                                kernel_initializer=initializer, use_bias=False))\n",
        "\n",
        "    if apply_batchnorm:\n",
        "        result.add(tf.keras.layers.BatchNormalization())\n",
        "        result.add(tf.keras.layers.Lambda(lambda x: tf.where(tf.math.is_nan(x), tf.zeros_like(x), x)))\n",
        "\n",
        "    result.add(tf.keras.layers.LeakyReLU())\n",
        "\n",
        "    return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "99q97Llw90Qg"
      },
      "outputs": [],
      "source": [
        "def upsample(filters, size, h, w, apply_dropout=False):\n",
        "    initializer = tf.random_normal_initializer(0., 0.02)\n",
        "\n",
        "    result = tf.keras.Sequential()\n",
        "\n",
        "    result.add(\n",
        "        tf.keras.layers.Conv2DTranspose(filters, size, strides=2,\n",
        "                                        padding='same',\n",
        "                                        kernel_initializer=initializer,\n",
        "                                        use_bias=False))\n",
        "\n",
        "    result.add(tf.keras.layers.BatchNormalization())\n",
        "    result.add(tf.keras.layers.Lambda(lambda x: tf.where(tf.math.is_nan(x), tf.zeros_like(x), x)))\n",
        "\n",
        "    if apply_dropout:\n",
        "        result.add(tf.keras.layers.Dropout(0.5))\n",
        "\n",
        "    result.add(tf.keras.layers.ReLU())\n",
        "\n",
        "    return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J1jpzHJb94dz"
      },
      "outputs": [],
      "source": [
        "def Generator():\n",
        "        down_stack = [\n",
        "            downsample(64, 4, apply_batchnorm=False),  # (bs, 128, 256, 64)\n",
        "            downsample(128, 4),  # (bs, 64, 128, 128)\n",
        "            downsample(256, 4),  # (bs, 32, 64, 256)\n",
        "            downsample(512, 4),  # (bs, 16, 32, 512)\n",
        "            downsample(512, 4),  # (bs, 8, 16, 512)\n",
        "            downsample(512, 4),  # (bs, 4, 8, 512)\n",
        "            downsample(512, 4),  # (bs, 2, 4, 512)\n",
        "            downsample(512, 4),  # (bs, 1, 2, 512)\n",
        "        ]\n",
        "\n",
        "        up_stack = [\n",
        "            upsample(512, 4, 1, 2, apply_dropout=True),  # (bs, 2, 4, 1024)\n",
        "            upsample(512, 4, 2, 4, apply_dropout=True),  # (bs, 4, 8, 1024)\n",
        "            upsample(512, 4, 4, 8, apply_dropout=True),  # (bs, 8, 16, 1024)\n",
        "            upsample(512, 4, 8, 16),  # (bs, 16, 32, 1024)\n",
        "            upsample(256, 4, 16, 32),  # (bs, 32, 64, 512)\n",
        "            upsample(128, 4, 32, 64),  # (bs, 64, 128, 256)\n",
        "            upsample(64, 4, 64, 128),  # (bs, 128, 256, 128)\n",
        "        ]\n",
        "\n",
        "        initializer = tf.random_normal_initializer(0., 0.02)\n",
        "        last_upsample = upsample(64, 4, 128, 256)\n",
        "        last = tf.keras.layers.Conv2D(OUTPUT_CHANNELS, 4, strides=1, padding='same', kernel_initializer=initializer, activation='tanh')  # (bs, 256, 512, 3)\n",
        "\n",
        "        concat = tf.keras.layers.Concatenate()\n",
        "        inputs = tf.keras.layers.Input(shape=[256, 512, 3])\n",
        "\n",
        "        x = inputs\n",
        "\n",
        "        # Downsampling through the model\n",
        "        skips = []\n",
        "        for down in down_stack:\n",
        "            x = down(x)\n",
        "            skips.append(x)\n",
        "\n",
        "        skips = reversed(skips[:-1])\n",
        "\n",
        "        # Upsampling and establishing the skip connections\n",
        "        for up, skip in zip(up_stack, skips):\n",
        "            x = up(x)\n",
        "            x = concat([x, skip])\n",
        "\n",
        "        x = last_upsample(x)\n",
        "        x = last(x)\n",
        "\n",
        "        return tf.keras.Model(inputs=inputs, outputs=x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q19L4e74_qMF"
      },
      "outputs": [],
      "source": [
        "def Discriminator():\n",
        "    initializer = tf.random_normal_initializer(0., 0.02)\n",
        "\n",
        "    inp = tf.keras.layers.Input(shape=[256, 512, 3], name='input_image')\n",
        "    tar = tf.keras.layers.Input(shape=[256, 512, 3], name='target_image')\n",
        "\n",
        "    x = tf.keras.layers.concatenate([inp, tar])  # (bs, 256, 512, channels*2)\n",
        "\n",
        "    down1 = downsample(64, 4, False)(x)  # (bs, 128, 256, 64)\n",
        "    down2 = downsample(128, 4)(down1)  # (bs, 64, 128, 128)\n",
        "    down3 = downsample(256, 4)(down2)  # (bs, 32, 64, 256)\n",
        "\n",
        "    zero_pad1 = tf.keras.layers.ZeroPadding2D()(down3)  # (bs, 34, 66, 256)\n",
        "    conv = tf.keras.layers.Conv2D(512, 4, strides=1,\n",
        "                                  kernel_initializer=initializer,\n",
        "                                  use_bias=False)(zero_pad1)  # (bs, 31, 63, 512)\n",
        "\n",
        "    batchnorm1 = tf.keras.layers.BatchNormalization()(conv)\n",
        "\n",
        "    leaky_relu = tf.keras.layers.LeakyReLU()(batchnorm1)\n",
        "\n",
        "    zero_pad2 = tf.keras.layers.ZeroPadding2D()(leaky_relu)  # (bs, 33, 65, 512)\n",
        "\n",
        "    last = tf.keras.layers.Conv2D(1, 4, strides=1,\n",
        "                                  kernel_initializer=initializer)(zero_pad2)  # (bs, 30, 62, 1)\n",
        "\n",
        "    return tf.keras.Model(inputs=[inp, tar], outputs=last)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lX2Jl_9mBOy3"
      },
      "outputs": [],
      "source": [
        "generator = Generator()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JOCE71p3BQiq"
      },
      "outputs": [],
      "source": [
        "discriminator = Discriminator()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wVn1pO1Tt0FP"
      },
      "source": [
        "#GAN parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dt56rJXEt2mJ"
      },
      "outputs": [],
      "source": [
        "loss_object = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
        "LAMBDA = 100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qfHZ3OMQt51Z"
      },
      "outputs": [],
      "source": [
        "def discriminator_loss(disc_real_output, disc_generated_output):\n",
        "    real_loss = loss_object(tf.ones_like(disc_real_output), disc_real_output)\n",
        "\n",
        "    generated_loss = loss_object(tf.zeros_like(disc_generated_output), disc_generated_output)\n",
        "\n",
        "    total_disc_loss = real_loss + generated_loss\n",
        "\n",
        "    return total_disc_loss\n",
        "\n",
        "def generator_loss( disc_generated_output, gen_output, target):\n",
        "    gan_loss = loss_object(tf.ones_like(disc_generated_output), disc_generated_output)\n",
        "\n",
        "    # mean absolute error\n",
        "    l1_loss = tf.reduce_mean(tf.abs(target - gen_output))\n",
        "\n",
        "    total_gen_loss = gan_loss + (LAMBDA * l1_loss)\n",
        "\n",
        "    return total_gen_loss, gan_loss, l1_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B4wObMWlt57K"
      },
      "outputs": [],
      "source": [
        "lr = 2e-4\n",
        "generator_optimizer = tf.keras.optimizers.legacy.Adam(lr, beta_1=0.5)\n",
        "discriminator_optimizer = tf.keras.optimizers.legacy.Adam(lr, beta_1=0.9)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Jp2RS7jb5YX"
      },
      "source": [
        "#Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ddE1TvMQB-M8"
      },
      "outputs": [],
      "source": [
        "checkpoint_dir = '/content/drive/MyDrive/Scriptie/ckpt/P2P/TransposeConv'\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
        "checkpoint = tf.train.Checkpoint(generator_optimizer=generator_optimizer,\n",
        "                                 discriminator_optimizer=discriminator_optimizer,\n",
        "                                 generator=generator,\n",
        "                                 discriminator=discriminator)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yK-QH8n0B3GQ"
      },
      "outputs": [],
      "source": [
        "def generate_images(model, test_input, tar, mask):  \n",
        "  prediction = model(test_input, training=True)\n",
        "  prediction = prediction*mask+tar*(1-mask)\n",
        "  plt.figure(figsize=(15, 15))\n",
        "\n",
        "  display_list = [test_input[0], tar[0], prediction[0]]\n",
        "  title = ['Input Image', 'Ground Truth', 'Predicted Image']\n",
        "\n",
        "  for i in range(3):\n",
        "    plt.subplot(1, 3, i+1)\n",
        "    plt.title(title[i])\n",
        "    # Getting the pixel values in the [0, 1] range to plot.\n",
        "    plt.imshow(display_list[i] * 0.5 + 0.5)\n",
        "    plt.axis('off')\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ER0tZNQdcAjL"
      },
      "source": [
        "##Steps"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MSfUwKPjCXYp"
      },
      "outputs": [],
      "source": [
        "@tf.function\n",
        "def train_step(input_image, mask, target, epoch):\n",
        "  with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
        "    gen_output = generator([input_image], training=True) #generate image based on input\n",
        "    gen_output = gen_output*mask+ target*(1-mask) #combine generated patches with valid pixels from ground truth\n",
        "\n",
        "    disc_real_output = discriminator([input_image, target], training=True) #calculate discriminator loss for ground truth images\n",
        "    disc_generated_output = discriminator([input_image, gen_output], training=True) #calculate discriminator loss for predicted images\n",
        "\n",
        "    gen_total_loss, gen_gan_loss, gen_l1_loss = generator_loss(disc_generated_output, gen_output, target)\n",
        "    disc_loss = discriminator_loss(disc_real_output, disc_generated_output)\n",
        "\n",
        "  generator_gradients = gen_tape.gradient(gen_total_loss,\n",
        "                                          generator.trainable_variables)\n",
        "  discriminator_gradients = disc_tape.gradient(disc_loss,\n",
        "                                               discriminator.trainable_variables)\n",
        "\n",
        "  generator_optimizer.apply_gradients(zip(generator_gradients,\n",
        "                                          generator.trainable_variables))\n",
        "  discriminator_optimizer.apply_gradients(zip(discriminator_gradients,\n",
        "                                              discriminator.trainable_variables))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ogh3Se3wB47H"
      },
      "outputs": [],
      "source": [
        "log_dir=\"/content/drive/MyDrive/Scriptie/logs/im_generator/P2P/Upsample/steps/\"\n",
        "\n",
        "summary_writer = tf.summary.create_file_writer(\n",
        "  log_dir + \"fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1RUjquDqCZo1"
      },
      "outputs": [],
      "source": [
        "def fit(train_ds, test_ds, steps):\n",
        "  example_input, example_target, mask_test, path, locations = next(iter(test_ds.take(1)))\n",
        "  #example_input, example_target, mask_test = next(iter(test_ds.take(1)))\n",
        "  start = time.time()\n",
        "\n",
        "  for step, (input_image, target, mask, path, locations) in train_ds.repeat().take(steps).enumerate():\n",
        "    if (step) % 1000 == 0:\n",
        "      display.clear_output(wait=True)\n",
        "\n",
        "      if step != 0:\n",
        "        print(f'Time taken for 1000 steps: {time.time()-start:.2f} sec\\n')\n",
        "\n",
        "      start = time.time()\n",
        "\n",
        "      generate_images(generator, example_input, example_target, mask_test)\n",
        "      print(f\"Step: {step//1000}k\")\n",
        "    \n",
        "    \n",
        "    #ones_x = tf.ones_like(input_image)[:, :, :, 0:1]\n",
        "    #input_image = tf.concat([input_image, ones_x, ones_x*mask], axis=3)\n",
        "    \n",
        "    train_step(input_image, mask, target, step)\n",
        "\n",
        "    # Training step\n",
        "    if (step+1) % 10 == 0:\n",
        "      print('.', end='', flush=True)\n",
        "\n",
        "\n",
        "    # Save (checkpoint) the model every 5k steps\n",
        "    #if (step + 1) % 5000 == 0:\n",
        "    #  checkpoint.save(file_prefix=checkpoint_prefix)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gKZPywWbcFcY"
      },
      "source": [
        "##Epoch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A5IBcIQ8MhaX"
      },
      "outputs": [],
      "source": [
        "@tf.function\n",
        "def train_epoch(input_image, mask, target):\n",
        "  with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
        "    gen_output = generator(input_image, training=True)\n",
        "    gen_output = gen_output*mask+ target*(1-mask) #combine generated patches with valid pixels from ground truth\n",
        "\n",
        "    disc_real_output = discriminator([input_image, target], training=True)\n",
        "    disc_generated_output = discriminator([input_image, gen_output], training=True) #discriminator takes predicted labels\n",
        "\n",
        "    gen_total_loss, gen_gan_loss, gen_CE_loss = generator_loss(disc_generated_output, gen_output, target) #CE loss of 35 channel output\n",
        "    disc_loss = discriminator_loss(disc_real_output, disc_generated_output)\n",
        "\n",
        "  generator_gradients = gen_tape.gradient(gen_total_loss,\n",
        "                                          generator.trainable_variables)\n",
        "  discriminator_gradients = disc_tape.gradient(disc_loss,\n",
        "                                              discriminator.trainable_variables)\n",
        "\n",
        "  generator_optimizer.apply_gradients(zip(generator_gradients, generator.trainable_variables))\n",
        "  discriminator_optimizer.apply_gradients(zip(discriminator_gradients, discriminator.trainable_variables))\n",
        "  \n",
        "  return gen_total_loss, gen_gan_loss, gen_CE_loss, disc_loss\n",
        "    \n",
        "  \n",
        "def getValAccLoss(input_image, mask, target): \n",
        "  gen_output = generator(input_image, training=True)\n",
        "  gen_output = gen_output*mask+ target*(1-mask) #convert the 35 channel output of the generator to a 1 channel output with labels\n",
        "\n",
        "  disc_real_output = discriminator([input_image, target], training=True)\n",
        "  disc_generated_output = discriminator([input_image, gen_output], training=True) #discriminator takes predicted labels\n",
        "\n",
        "  gen_total_loss, gen_gan_loss, gen_CE_loss = generator_loss(disc_generated_output, gen_output, target) #CE loss of 35 channel output\n",
        "  disc_loss = discriminator_loss(disc_real_output, disc_generated_output)\n",
        "\n",
        "\n",
        "  return gen_total_loss, gen_gan_loss, gen_CE_loss, disc_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ROWX2zF375Yu"
      },
      "outputs": [],
      "source": [
        "log_dir= '/content/drive/MyDrive/Scriptie/logs/Experiment'\n",
        "summary_writer_train = tf.summary.create_file_writer(log_dir + \"/fit/combined/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")+\"_TrainFT\")\n",
        "summary_writer_val = tf.summary.create_file_writer(log_dir + \"/fit/combined/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")+\"_ValFT\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AtfCduxyNpDc"
      },
      "outputs": [],
      "source": [
        "def fit(train_ds, test_ds, epochs):\n",
        "  example_input, example_target, mask_test, path, locations = next(iter(test_ds.take(1)))\n",
        "  example_input, example_target, mask_test\n",
        "  start = time.time()\n",
        "  total_ims = tf.cast(train_ds.cardinality(), tf.float32)\n",
        "  total_ims_val = tf.cast(test_ds.cardinality(), tf.float32)\n",
        "\n",
        "  for epoch in range(epochs):\n",
        "    metrics_dict = {\"gen_total_loss\":0, \"gen_gan_loss\":0, \"gen_L1_loss\":0, \"disc_loss\":0}\n",
        "    generate_images(generator, example_input, example_target, mask_test)\n",
        "\n",
        "    print(\"Start training of epoch: \", epoch+1)\n",
        "    for step,(input_image, target, mask, path, locations) in train_ds.enumerate():\n",
        "      gen_total_loss, gen_gan_loss, gen_L1_loss, disc_loss = train_epoch(input_image, mask, target)\n",
        "      metrics_list = (gen_total_loss, gen_gan_loss, gen_L1_loss, disc_loss)\n",
        "      \n",
        "      for i,(key,value) in enumerate(metrics_dict.items()):\n",
        "        metrics_dict[key] = value + metrics_list[i]\n",
        "      \n",
        "      if (step+1) % 50 == 0:\n",
        "        print('.', end='', flush=True)\n",
        "\n",
        "    with summary_writer_train.as_default():\n",
        "      tf.summary.scalar('gen_total_loss', metrics_dict[\"gen_total_loss\"]/total_ims, step=epoch)\n",
        "      tf.summary.scalar('gen_gan_loss', metrics_dict[\"gen_gan_loss\"]/total_ims, step=epoch)\n",
        "      tf.summary.scalar('gen_L1_loss', metrics_dict[\"gen_L1_loss\"]/total_ims, step=epoch)\n",
        "      tf.summary.scalar('disc_loss', metrics_dict[\"disc_loss\"]/total_ims, step=epoch)\n",
        "\n",
        "    \n",
        "    # Gather the metrics for the validation set\n",
        "    metrics_dict_val = {\"gen_total_loss\":0, \"gen_gan_loss\":0, \"gen_L1_loss\":0, \"disc_loss\":0}\n",
        "    print(\"Gathering validation set metrics...\")\n",
        "    for step,(input_image, target, mask, path, locations) in test_ds.enumerate():\n",
        "      gen_total_loss, gen_gan_loss, gen_L1_loss, disc_loss = getValAccLoss(input_image, mask, target)\n",
        "      metrics_list_val = (gen_total_loss, gen_gan_loss, gen_L1_loss, disc_loss)\n",
        "        \n",
        "      for i,(key,value) in enumerate(metrics_dict_val.items()):\n",
        "        metrics_dict_val[key] = value + metrics_list_val[i]\n",
        "    \n",
        "    with summary_writer_val.as_default():\n",
        "      tf.summary.scalar('gen_total_loss', metrics_dict_val[\"gen_total_loss\"]/total_ims_val, step=epoch)\n",
        "      tf.summary.scalar('gen_gan_loss', metrics_dict_val[\"gen_gan_loss\"]/total_ims_val, step=epoch)\n",
        "      tf.summary.scalar('gen_L1_loss', metrics_dict_val[\"gen_L1_loss\"]/total_ims_val, step=epoch)\n",
        "      tf.summary.scalar('disc_loss', metrics_dict_val[\"disc_loss\"]/total_ims_val, step=epoch)\n",
        "\n",
        "    display.clear_output(wait=True)\n",
        "    print(f'Time taken for 1 epoch: {time.time()-start:.2f} sec\\n')\n",
        "    start = time.time()\n",
        "\n",
        "    # Save (checkpoint) the model every 5 epochs\n",
        "    #if epoch % 5 == 0 & epoch !=0: \n",
        "    #  checkpoint.save(file_prefix=checkpoint_prefix)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tuewArASnhC7"
      },
      "source": [
        "#Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ActfhxSKCbaX"
      },
      "outputs": [],
      "source": [
        "%reload_ext tensorboard\n",
        "%tensorboard --logdir {log_dir}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6cTUQDwhCdIl"
      },
      "outputs": [],
      "source": [
        "fit(tf_train, tf_val, 20)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pZW2bZwaDoy7"
      },
      "source": [
        "# Metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IWqGQnJKDnRw"
      },
      "outputs": [],
      "source": [
        "def metrics(image_1, image_2):\n",
        "  # calculate L1 distance\n",
        "  L1_distance = tf.math.reduce_sum(tf.math.abs(image_1 - image_2))\n",
        "  ssim = tf.image.ssim(image_1, image_2, 2.0)\n",
        "  psnr = tf.image.psnr(image_1, image_2, 2.0)\n",
        "  return [L1_distance.numpy(), ssim.numpy()[0], psnr.numpy()[0]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tS1J2xT1mhgv"
      },
      "outputs": [],
      "source": [
        "def splitMaskMetrics(target, prediction, locations):\n",
        "    locations = np.squeeze(locations.numpy(), axis = 0)\n",
        "    ssim_list = []\n",
        "    psnr_list = []\n",
        "\n",
        "    for location in locations:\n",
        "        mask_height = tf.cast(location[0]/2, tf.int32).numpy()\n",
        "        mask_width = tf.cast(location[1]/2, tf.int32).numpy()\n",
        "        height_offset = location[2]\n",
        "        width_offset = location[3]\n",
        "\n",
        "        targetMask = target[:, height_offset-mask_height:height_offset+mask_height, width_offset-mask_width:width_offset+mask_width,:]\n",
        "        predictiontMask = prediction[:, height_offset-mask_height:height_offset+mask_height, width_offset-mask_width:width_offset+mask_width, :] \n",
        "\n",
        "        ssim = tf.image.ssim(targetMask, predictiontMask, 2.0)\n",
        "        psnr = tf.image.psnr(targetMask, predictiontMask, 2.0)\n",
        "\n",
        "\n",
        "        ssim_list.append(ssim.numpy()[0])\n",
        "        psnr_list.append(psnr.numpy()[0])\n",
        "    \n",
        "\n",
        "    l1 = tf.math.reduce_sum(tf.math.abs(target-prediction))\n",
        "\n",
        "    return [l1.numpy(), sum(ssim_list)/len(ssim_list), sum(psnr_list)/len(psnr_list)]\n",
        "\n",
        "def get_dataset_metrics(ds):\n",
        "  #input_image is the inpainted image, GT is the groundtruth\n",
        "  names = [\"L1\",\"SSIM\",\"PSNR\"]\n",
        "  metrics_list = []\n",
        "  img_path_list = []\n",
        "  mask_list = []\n",
        "  \n",
        "  for (masked_image, image, mask, image_file, locations) in ds:\n",
        "    prediction = generator(masked_image, training=True) #estimated values for each of 35 classes\n",
        "    prediction = prediction * mask + image*(1-mask) #insert generated label patches to inverted ground truth\n",
        "\n",
        "    metrics_list.append(splitMaskMetrics(image, prediction, locations))\n",
        "    #img_path_list.append(image_file[i].numpy()[0].decode(\"utf-8\"))\n",
        "    #mask_list.append(mask[i])\n",
        "    \n",
        "  \n",
        "  metrics_df = pd.DataFrame(metrics_list)\n",
        "  metrics_df.columns = names\n",
        "  #metrics_df[\"Img Path\"] = img_path_list\n",
        "  #metrics_df[\"Mask\"] = mask_list\n",
        "  return metrics_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1wTLJzBA6dKF"
      },
      "outputs": [],
      "source": [
        "metrics_test = get_dataset_metrics(tf_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8wvd0rQkkoKS"
      },
      "outputs": [],
      "source": [
        "with open(\"/content/drive/MyDrive/Scriptie/json/GAN_metrics.json\", 'w') as j:\n",
        "  json.dump(GAN_metrics, j, indent = 6)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "onBvPUiWhCi0"
      },
      "outputs": [],
      "source": [
        "def reconstruct_img(image_file, mask):\n",
        "  image = load(image_file, 3)\n",
        "  image = resize(image, 256, 512)\n",
        "  masked_image = (1-mask)*image\n",
        "  image = normalize(image)\n",
        "  masked_image = normalize(masked_image)\n",
        "  \n",
        "\n",
        "  return image, masked_image, mask"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MVn9C-nspXkS"
      },
      "outputs": [],
      "source": [
        "def show_img(img_tuple):\n",
        "  target, input_image, mask = img_tuple\n",
        "  target = tf.expand_dims(target, 0)\n",
        "\n",
        "  predicted = generator(input_image, training=True)\n",
        "  predicted = predicted * mask + target*(1-mask)\n",
        "  \n",
        "\n",
        "  images = [input_image[0], target[0], predicted[0]]\n",
        "  title = [\"Input Image\", \"Ground Truth\", \"Predicted Image\"]\n",
        "  plt.figure(figsize=(15, 15))\n",
        "\n",
        "  for i, image in enumerate(images):\n",
        "    plt.subplot(3,1,i+1)\n",
        "    plt.title(title[i])\n",
        "    plt.imshow(image*0.5+0.5)\n",
        "    plt.axis('off')\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RWG2Hr99REgb"
      },
      "outputs": [],
      "source": [
        "rand_idx = randint(0,tf_val.cardinality())\n",
        "img_idx = rand_idx\n",
        "RecImages = reconstruct_img(metrics_test[\"Img Path\"][img_idx], metrics_test[\"Mask\"][img_idx])\n",
        "show_img(RecImages)\n",
        "print(metrics_test[[\"L1\",\"SSIM\",\"PSNR\"]].loc[[img_idx]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_ud-t0UFbFSz"
      },
      "outputs": [],
      "source": [
        "def analyse_checkpoints(path_to_ckpts):\n",
        "  list_ckpts = os.listdir(path_to_ckpts)\n",
        "  #list_ckpts = list(filter(lambda name: name[-20:] == \".data-00000-of-00001\", list_ckpts))\n",
        "  list_ckpts = [name[:-20] for name in list_ckpts if name[-20:]== \".data-00000-of-00001\"]\n",
        "  metrics = {}\n",
        "\n",
        "\n",
        "  for ckpt in list_ckpts:\n",
        "    metrics[ckpt] = {}\n",
        "    checkpoint.restore(os.path.join(path_to_ckpts, ckpt))\n",
        "    metrics_df = get_dataset_metrics(tf_val)\n",
        "    metrics[ckpt][\"mean\"] = list(metrics_df[[\"L1\",\"SSIM\",\"PSNR\"]].mean())\n",
        "    metrics[ckpt][\"max\"] = list(metrics_df[[\"L1\",\"SSIM\",\"PSNR\"]].max())\n",
        "    metrics[ckpt][\"min\"] = list(metrics_df[[\"L1\",\"SSIM\",\"PSNR\"]].min())\n",
        "    metrics[ckpt][\"median\"] = list(metrics_df[[\"L1\",\"SSIM\",\"PSNR\"]].median())\n",
        "  \n",
        "  return metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x6o1qEbjN_Es"
      },
      "outputs": [],
      "source": [
        "metrics_ckpts = analyse_checkpoints(\"/content/drive/MyDrive/Scriptie/ckpt/P2P/upsample\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UKCemOPqTX6B"
      },
      "outputs": [],
      "source": [
        "for m in [\"mean\", \"median\", \"min\", \"max\"]:\n",
        "  print(m)\n",
        "  for key, value in metrics_ckpts.items():\n",
        "    print(key, value[m])\n",
        "  print(\" \")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "edgUm_B1ujbx"
      },
      "outputs": [],
      "source": [
        "for i in tf_val_filtered.take(1):\n",
        "  masked_image, image, mask, image_file = i"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6wkL-E7EZ7mM"
      },
      "source": [
        "#Fine tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WmGCOpqiXFPl"
      },
      "outputs": [],
      "source": [
        "# Fill pandas dataframe with the paths to the files\n",
        "def folder_to_pd(image_dir, semantics_dir):\n",
        "  image_paths = {\"test\": [], \"train\": [], \"val\": []}\n",
        "  semantics_paths = {\"test\": [], \"train\": [], \"val\": []}\n",
        "  label_paths = {\"test\": [], \"train\": [], \"val\": []}\n",
        "\n",
        "\n",
        "  for data_type in [\"test\", \"train\", \"val\"]:\n",
        "    image_subdir = os.path.join(image_dir, data_type)\n",
        "    for root, subdir, files in os.walk(image_subdir):\n",
        "      subdir.sort()\n",
        "      files.sort()\n",
        "      if files:\n",
        "        for file in files:\n",
        "          image_paths[data_type].append(os.path.join(root, file))\n",
        "\n",
        "    semantics_subdir = os.path.join(semantics_dir, data_type)\n",
        "    for root, subdir, files in os.walk(semantics_subdir):\n",
        "      subdir.sort()\n",
        "      files.sort()\n",
        "      if files:\n",
        "        for i,file in enumerate(files):\n",
        "          if file[-12:] == \"labelIds.png\":\n",
        "            semantics_paths[data_type].append(os.path.join(root, file))\n",
        "          if file[-5:] == \".json\":\n",
        "            label_paths[data_type].append(os.path.join(root, file))\n",
        "  \n",
        "  test_ds = pd.DataFrame(list(zip(image_paths[\"test\"], semantics_paths[\"test\"], label_paths[\"test\"])), columns =['image', 'labelIds', 'json'])\n",
        "  train_ds = pd.DataFrame(list(zip(image_paths[\"train\"], semantics_paths[\"train\"], label_paths[\"train\"])), columns =['image', 'labelIds', 'json'])\n",
        "  val_ds = pd.DataFrame(list(zip(image_paths[\"val\"], semantics_paths[\"val\"], label_paths[\"val\"])), columns =['image', 'labelIds', 'json'])\n",
        "\n",
        "  return test_ds, train_ds, val_ds\n",
        "\n",
        "#Function that determines whether there is a person present in the image\n",
        "def flag_person(json_path):\n",
        "  person_present = False #Flag to determine whether person(s) are present in image\n",
        "  with open(json_path) as jsonFile:\n",
        "    jsonObject = json.load(jsonFile)\n",
        "    jsonFile.close()\n",
        "    for element in jsonObject[\"objects\"]:\n",
        "      if element[\"label\"] == \"person\":\n",
        "        return True\n",
        "  return False\n",
        "\n",
        "#function that filters out all the images without images in them\n",
        "# if filter persons is true, get all images WITHOUT person. If False get all images WITH persons\n",
        "def filter_ds(ds, filter_person = True):\n",
        "  json_list = ds[\"json\"]\n",
        "  drop_rows = [i for i,element in enumerate(json_list) if flag_person(element) == filter_person]\n",
        "  return ds.drop(drop_rows)\n",
        "\n",
        "# convert pandas dataframe to tensorflow dataset\n",
        "def pd_to_ds(pd_df):\n",
        "  return tf.data.Dataset.from_tensor_slices((pd_df[\"image\"], pd_df[\"labelIds\"], pd_df[\"json\"])) #returns dataset with image and labels for each element in the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "01YOWhYZetQx"
      },
      "outputs": [],
      "source": [
        "def personFilter(df):\n",
        "  df = df.reset_index()  # make sure indexes pair with number of rows\n",
        "  threshold = 35000 \n",
        "  drop_rows = [] # if less labeled pixels than threshold, drop the row\n",
        "\n",
        "  for index, row in df.iterrows():\n",
        "    labels = load(row[\"labelIds\"], 0)\n",
        "    binary_mask =  tf.math.equal(labels, 24)\n",
        "    count_labels = tf.math.count_nonzero(binary_mask)\n",
        "    if count_labels < threshold:\n",
        "      drop_rows.append(index)\n",
        "  \n",
        "  return df.drop(drop_rows)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J8x_OsDbJ_IP"
      },
      "outputs": [],
      "source": [
        "def create_person_masks(image_path, labels_path, json_path):\n",
        "  personID = 24\n",
        "  riderID = 25  \n",
        "  \n",
        "  image = load(image_path, 3)\n",
        "  image = resize(image, 256, 512)\n",
        "\n",
        "  labels = load(labels_path, 1)\n",
        "  labels = resize(labels, 256,512)\n",
        "\n",
        "\n",
        "  mask_person = tf.math.equal(labels, personID)\n",
        "  mask_person = tf.cast(mask_person, tf.float32) #zeros where persons are\n",
        "\n",
        "  mask_rider = tf.math.equal(labels, riderID)\n",
        "  mask_rider = tf.cast(mask_rider, tf.float32)\n",
        "\n",
        "  # merge masks\n",
        "  mask = mask_person + mask_rider\n",
        "\n",
        "  masked_image = image * (1-mask)\n",
        "  masked_image = normalize(masked_image)\n",
        "  image = normalize(image)\n",
        "\n",
        "  return masked_image, image, mask"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m0A4ZA8KaJkR"
      },
      "outputs": [],
      "source": [
        "#Create fine tuning datasets\n",
        "FT_test_ds, FT_train_ds, FT_val_ds = folder_to_pd(\"/content/cityScapes/img/leftImg8bit\", \"/content/cityScapes/annotations/gtFine\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XjU5SZrYhEPy"
      },
      "outputs": [],
      "source": [
        "large_persons_train = personFilter(FT_train_ds)\n",
        "large_persons_val = personFilter(FT_val_ds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "778Vll2jldcW"
      },
      "outputs": [],
      "source": [
        "# Dataset is heeft nu pad naar foto, semantics en json\n",
        "# grote hoeveelheden labels van mensen\n",
        "# hiervan masks maken en deze opslaan op drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wxyq3YG1iT6A"
      },
      "outputs": [],
      "source": [
        "large_persons_train = pd_to_ds(large_persons_train)\n",
        "large_persons_val = pd_to_ds(large_persons_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LrrK-JSZPlSj"
      },
      "outputs": [],
      "source": [
        "person_mask_train = large_persons_train.map(create_person_masks, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "person_mask_train = person_mask_train.batch(BATCH_SIZE)\n",
        "person_mask_train = person_mask_train.prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "person_mask_val = large_persons_val.map(create_person_masks, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "person_mask_val = person_mask_val.batch(BATCH_SIZE)\n",
        "person_mask_val = person_mask_val.prefetch(tf.data.AUTOTUNE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L0JkEEVWQAX6"
      },
      "outputs": [],
      "source": [
        "def save_mask_ds(ds, path):\n",
        "  for i, mask in ds.enumerate():\n",
        "    mask = mask[0]\n",
        "    name = path + \"_\" + str(i.numpy())+ \".png\"\n",
        "    tf.keras.utils.save_img(name, mask, data_format= \"channels_last\")\n",
        "    \n",
        "    mirror_name = path + \"_\" + str(i.numpy()) + \"mirror\" + \".png\"\n",
        "    reverse = tf.reverse(mask, [1])\n",
        "    tf.keras.utils.save_img(mirror_name, reverse, data_format= \"channels_last\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X2z3wFGUTaSd"
      },
      "outputs": [],
      "source": [
        "#save_mask_ds(person_mask_val, \"/content/drive/MyDrive/Scriptie/masks/val/val\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PQgXeBNJb_aI"
      },
      "outputs": [],
      "source": [
        "# dataset with where each element is a tuple (path_to_image, path_to_labels) \n",
        "train_noPersons = pd_to_ds(filter_ds(FT_train_ds))\n",
        "val_noPersons = pd_to_ds(filter_ds(FT_val_ds))\n",
        "\n",
        "train_persons = pd_to_ds(filter_ds(FT_train_ds, False))\n",
        "val_persons = pd_to_ds(filter_ds(FT_val_ds, False))\n",
        "\n",
        "print(\"Training dataset WITHOUT persons has\", train_noPersons.cardinality().numpy(), \"elements.\")\n",
        "print(\"Validation dataset WITHOUT persons has\", val_noPersons.cardinality().numpy(), \"elements.\")\n",
        "print(\"\")\n",
        "print(\"Training dataset WITH persons has\", train_persons.cardinality().numpy(), \"elements.\")\n",
        "print(\"Validation dataset WITH persons has\", val_persons.cardinality().numpy(), \"elements.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MiZEIGpqaz0c"
      },
      "outputs": [],
      "source": [
        "val_noPersons = val_noPersons.map(create_person_masks, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "val_noPersons = val_noPersons.batch(BATCH_SIZE)\n",
        "val_noPersons = val_noPersons.prefetch(tf.data.AUTOTUNE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rSYBX_ZKdrgf"
      },
      "outputs": [],
      "source": [
        "for i, (masked_image, image, mask) in person_mask_val.enumerate():\n",
        "  prediction = generator(image, training = True)\n",
        "  prediction = mask * prediction + image * (1-mask)\n",
        "  fix, axs = plt.subplots(1,3, figsize = (20,20))\n",
        "  axs[0].imshow(image[0]*0.5+0.5)\n",
        "  axs[1].imshow(masked_image[0]*0.5+0.5)\n",
        "  axs[2].imshow(prediction[0]*0.5+0.5)\n",
        "  axs[0].axis(\"off\")\n",
        "  axs[1].axis(\"off\")\n",
        "  axs[2].axis(\"off\")\n",
        "  plt.show()\n",
        "\n",
        "  if i ==10:\n",
        "    break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "smwg1P3sZ8gy"
      },
      "outputs": [],
      "source": [
        "for image, mask in val_noPersons.take(1):\n",
        "  image = image[0]\n",
        "  plt.imshow(image*0.5+0.5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xl11oyPq47y7"
      },
      "outputs": [],
      "source": [
        "for i, (masked_image, image, mask) in person_mask_val.enumerate():"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eQYropbV472n"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TTsdPTWv475n"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GITNjwVpcQfb"
      },
      "outputs": [],
      "source": [
        "plt.imshow(mask[0,:,:,-1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wCWIYWH3ioGR"
      },
      "outputs": [],
      "source": [
        "masks = tf.data.Dataset.list_files(\"/content/drive/MyDrive/Scriptie/masks/train/*\")\n",
        "train_noPersons = tf.data.Dataset.zip((train_noPersons, masks))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4eIM5BVVJPN4"
      },
      "outputs": [],
      "source": [
        "masks_val = tf.data.Dataset.list_files(\"/content/drive/MyDrive/Scriptie/masks/val/*\")\n",
        "val_noPersons = tf.data.Dataset.zip((val_noPersons, masks_val))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_KaNhNBofaqk"
      },
      "outputs": [],
      "source": [
        "def person_mask(labelIm):\n",
        "  #labelID used for persons is 24 and for rider is 25\n",
        "  personID = 24\n",
        "  riderID = 25\n",
        "  mask_person = tf.math.equal(labelIm, personID)\n",
        "  mask_person = tf.cast(mask_person, tf.float32) #zeros where persons are\n",
        "\n",
        "  mask_rider = tf.math.equal(labelIm, riderID)\n",
        "  mask_rider = tf.cast(mask_rider, tf.float32)\n",
        "\n",
        "  # merge masks\n",
        "  mask = mask_person + mask_rider\n",
        "\n",
        "  return mask"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wDG26aMVvEia"
      },
      "outputs": [],
      "source": [
        "def load_images_CS(info, mask):\n",
        "  mask = load(mask, 0)\n",
        "  mask = mask /255\n",
        "\n",
        "  image_file, labels_file, json_file = info\n",
        "  image = load(image_file, 3)\n",
        "  image = resize(image, 256,512)\n",
        "  masked_image = image * (1-mask)\n",
        "  image = normalize(image)\n",
        "  masked_image = normalize(masked_image)\n",
        "  \n",
        "  \n",
        "\n",
        "  labels = load(labels_file, 0)\n",
        "  labels = resize(labels, 256,512)\n",
        "  masked_labels = labels * (1-mask)\n",
        "\n",
        "  return image, masked_image, labels, masked_labels, mask"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6q2xrRR3Rusx"
      },
      "outputs": [],
      "source": [
        "\"/content/drive/MyDrive/Scriptie/Cityscapes/No_persons\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TLYosG2qJHS1"
      },
      "outputs": [],
      "source": [
        "val_noPersons"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TRPEpXDgu4xJ"
      },
      "outputs": [],
      "source": [
        "finetune_train = train_noPersons.shuffle(train_noPersons.cardinality(), reshuffle_each_iteration=False)\n",
        "finetune_train = finetune_train.map(load_images_CS, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "finetune_train = finetune_train.batch(BATCH_SIZE)\n",
        "#train_noPersons = train_noPersons.cache(\"/content/temporary.tfcache\")\n",
        "finetune_train = finetune_train.prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "finetune_val = val_noPersons.shuffle(val_noPersons.cardinality(), reshuffle_each_iteration=False)\n",
        "finetune_val = finetune_val.map(load_images_CS, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "finetune_val = finetune_val.batch(BATCH_SIZE)\n",
        "#train_noPersons = train_noPersons.cache(\"/content/temporary.tfcache\")\n",
        "finetune_val = finetune_val.prefetch(tf.data.AUTOTUNE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-UqOiB3Qf6ff"
      },
      "outputs": [],
      "source": [
        "for image, masked_image, labels, masked_labels, mask in finetune_train.take(1):\n",
        "  plt.imshow(mask[0,:,:,-1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2iOM93zlhJYy"
      },
      "outputs": [],
      "source": [
        "plt.imshow(masked_image[0]*0.5+0.5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u-fKm1M9G_6m"
      },
      "outputs": [],
      "source": [
        "prediction = generator(masked_image, training = True)\n",
        "prediction = mask * prediction + image * (1-mask)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U7jJOW1WHD-G"
      },
      "outputs": [],
      "source": [
        "plt.imshow(prediction[0]*0.5+0.5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NtMZTedPo7Rs"
      },
      "outputs": [],
      "source": [
        "plt.imshow(image[0]*0.5+0.5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8q6UJ7SxHr__"
      },
      "source": [
        "## Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RIYzKMUEohxM"
      },
      "outputs": [],
      "source": [
        "generator_optimizer = tf.keras.optimizers.Adam(2e-5, beta_1=0.5)\n",
        "discriminator_optimizer = tf.keras.optimizers.Adam(2e-5, beta_1=0.5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xCmdroH8H5yy"
      },
      "outputs": [],
      "source": [
        "@tf.function\n",
        "def train_epoch(input_image, mask, target):\n",
        "  with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
        "    gen_output = generator(input_image, training=True)\n",
        "    gen_output = gen_output*mask+ target*(1-mask) #combine generated patches with valid pixels from ground truth\n",
        "\n",
        "    disc_real_output = discriminator([input_image, target], training=True)\n",
        "    disc_generated_output = discriminator([input_image, gen_output], training=True) #discriminator takes predicted labels\n",
        "\n",
        "    gen_total_loss, gen_gan_loss, gen_CE_loss = generator_loss(disc_generated_output, gen_output, target) #CE loss of 35 channel output\n",
        "    disc_loss = discriminator_loss(disc_real_output, disc_generated_output)\n",
        "\n",
        "  generator_gradients = gen_tape.gradient(gen_total_loss,\n",
        "                                          generator.trainable_variables)\n",
        "  discriminator_gradients = disc_tape.gradient(disc_loss,\n",
        "                                              discriminator.trainable_variables)\n",
        "\n",
        "  generator_optimizer.apply_gradients(zip(generator_gradients, generator.trainable_variables))\n",
        "  discriminator_optimizer.apply_gradients(zip(discriminator_gradients, discriminator.trainable_variables))\n",
        "  \n",
        "  return gen_total_loss, gen_gan_loss, gen_CE_loss, disc_loss\n",
        "    \n",
        "  \n",
        "def getValAccLoss(input_image, mask, target): \n",
        "  gen_output = generator(input_image, training=True)\n",
        "  gen_output = gen_output*mask+ target*(1-mask) #convert the 35 channel output of the generator to a 1 channel output with labels\n",
        "\n",
        "  disc_real_output = discriminator([input_image, target], training=True)\n",
        "  disc_generated_output = discriminator([input_image, gen_output], training=True) #discriminator takes predicted labels\n",
        "\n",
        "  gen_total_loss, gen_gan_loss, gen_CE_loss = generator_loss(disc_generated_output, gen_output, target) #CE loss of 35 channel output\n",
        "  disc_loss = discriminator_loss(disc_real_output, disc_generated_output)\n",
        "\n",
        "\n",
        "  return gen_total_loss, gen_gan_loss, gen_CE_loss, disc_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "90DB9T06H5yz"
      },
      "outputs": [],
      "source": [
        "log_dir= '/content/drive/MyDrive/Scriptie/logs/im_generator/P2P/TransposeConv/epoch/finetune/'\n",
        "summary_writer_train = tf.summary.create_file_writer(log_dir + \"fit/combined/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")+\"_TrainFT\")\n",
        "summary_writer_val = tf.summary.create_file_writer(log_dir + \"fit/combined/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")+\"_ValFT\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GJbRQi1QH5yz"
      },
      "outputs": [],
      "source": [
        "def fit(train_ds, test_ds, epochs):\n",
        "  #image, masked_image, labels, masked_labels, mask\n",
        "  example_target, example_input, labels_test, masked_labels_test, mask_test = next(iter(test_ds.take(1)))\n",
        "  example_input, example_target, mask_test\n",
        "  start = time.time()\n",
        "  total_ims = tf.cast(train_ds.cardinality(), tf.float32)\n",
        "  total_ims_val = tf.cast(test_ds.cardinality(), tf.float32)\n",
        "\n",
        "  for epoch in range(epochs):\n",
        "    metrics_dict = {\"gen_total_loss\":0, \"gen_gan_loss\":0, \"gen_L1_loss\":0, \"disc_loss\":0}\n",
        "    generate_images(generator, example_input, example_target, mask_test)\n",
        "\n",
        "    print(\"Start training of epoch: \", epoch+1)\n",
        "    for step,(target, input_image, labels, masked_labels, mask) in train_ds.enumerate():\n",
        "      gen_total_loss, gen_gan_loss, gen_L1_loss, disc_loss = train_epoch(input_image, mask, target)\n",
        "      metrics_list = (gen_total_loss, gen_gan_loss, gen_L1_loss, disc_loss)\n",
        "      \n",
        "      for i,(key,value) in enumerate(metrics_dict.items()):\n",
        "        metrics_dict[key] = value + metrics_list[i]\n",
        "      \n",
        "      if (step+1) % 50 == 0:\n",
        "        print('.', end='', flush=True)\n",
        "\n",
        "    with summary_writer_train.as_default():\n",
        "      tf.summary.scalar('gen_total_loss', metrics_dict[\"gen_total_loss\"]/total_ims, step=epoch)\n",
        "      tf.summary.scalar('gen_gan_loss', metrics_dict[\"gen_gan_loss\"]/total_ims, step=epoch)\n",
        "      tf.summary.scalar('gen_L1_loss', metrics_dict[\"gen_L1_loss\"]/total_ims, step=epoch)\n",
        "      tf.summary.scalar('disc_loss', metrics_dict[\"disc_loss\"]/total_ims, step=epoch)\n",
        "\n",
        "    \n",
        "    # Gather the metrics for the validation set\n",
        "    metrics_dict_val = {\"gen_total_loss\":0, \"gen_gan_loss\":0, \"gen_L1_loss\":0, \"disc_loss\":0}\n",
        "    print(\"Gathering validation set metrics...\")\n",
        "    for step,(target, input_image, labels, masked_labels, mask) in test_ds.enumerate():\n",
        "      gen_total_loss, gen_gan_loss, gen_L1_loss, disc_loss = getValAccLoss(input_image, mask, target)\n",
        "      metrics_list_val = (gen_total_loss, gen_gan_loss, gen_L1_loss, disc_loss)\n",
        "        \n",
        "      for i,(key,value) in enumerate(metrics_dict_val.items()):\n",
        "        metrics_dict_val[key] = value + metrics_list_val[i]\n",
        "    \n",
        "    with summary_writer_val.as_default():\n",
        "      tf.summary.scalar('gen_total_loss', metrics_dict_val[\"gen_total_loss\"]/total_ims_val, step=epoch)\n",
        "      tf.summary.scalar('gen_gan_loss', metrics_dict_val[\"gen_gan_loss\"]/total_ims_val, step=epoch)\n",
        "      tf.summary.scalar('gen_L1_loss', metrics_dict_val[\"gen_L1_loss\"]/total_ims_val, step=epoch)\n",
        "      tf.summary.scalar('disc_loss', metrics_dict_val[\"disc_loss\"]/total_ims_val, step=epoch)\n",
        "\n",
        "    display.clear_output(wait=True)\n",
        "    print(f'Time taken for 1 epoch: {time.time()-start:.2f} sec\\n')\n",
        "    start = time.time()\n",
        "\n",
        "    # Save (checkpoint) the model every 5 epochs\n",
        "    #if epoch % 5 == 0 & epoch !=0: \n",
        "    #  checkpoint.save(file_prefix=checkpoint_prefix)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y5qpGK55PGLP"
      },
      "outputs": [],
      "source": [
        "checkpoint_prefix = \"/content/drive/MyDrive/Scriptie/ckpt/finetune/GAN/ckpt\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QcVAlQM3PEyd"
      },
      "outputs": [],
      "source": [
        "checkpoint.save(file_prefix=checkpoint_prefix)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8dU30H6gItVx"
      },
      "outputs": [],
      "source": [
        "fit(finetune_train, finetune_val, 10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hRxReNFIvJVQ"
      },
      "outputs": [],
      "source": [
        "dataset = tf_train_filtered.take(9)\n",
        "for images in tf_train_filtered.take(9):\n",
        "  images = images\n",
        "  plt.figure(figsize=(15, 15))\n",
        "  num_images = 9\n",
        "  \n",
        "  for i in range(num_images):\n",
        "    plt.subplot(3, 3, i+1)\n",
        "    # Getting the pixel values in the [0, 1] range to plot.\n",
        "    plt.imshow(images[0][i] * 0.5 + 0.5)\n",
        "    plt.axis('off')\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BVa34Ggx2YYx"
      },
      "outputs": [],
      "source": [
        "title = [\"masked image\", \"GT\", \"mask\", \"prediction\"]\n",
        "predicted = generator(masked_image)\n",
        "predicted = predicted*mask+image*(1-mask)\n",
        "display_list = masked_image[0], image[0], mask[0,:,:,0], predicted[0]\n",
        "plt.figure(figsize=(30, 30))\n",
        "for i in range(4):\n",
        "  plt.subplot(1, 4, i+1)\n",
        "  plt.title(title[i])\n",
        "  # Getting the pixel values in the [0, 1] range to plot.\n",
        "  plt.imshow(display_list[i] * 0.5 + 0.5)\n",
        "  plt.axis('off')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xD66aXZ-ROEk"
      },
      "source": [
        "# Reducing data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qYQXLMz1nevE"
      },
      "outputs": [],
      "source": [
        "# loop\n",
        "## reduce training data\n",
        "## reset model\n",
        "## train model on data\n",
        "## get metrics (L1, PSNR, SSIM) means\n",
        "## save metrics"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\"\"\n",
        "std_dict = {'1.0': {'L1': [], 'PSNR': [], 'SSIM': []},\n",
        " '0.9': {'L1': [], 'PSNR': [], 'SSIM': []},\n",
        " '0.8': {'L1': [], 'PSNR': [], 'SSIM': []},\n",
        " '0.7': {'L1': [], 'PSNR': [], 'SSIM': []},\n",
        " '0.6': {'L1': [], 'PSNR': [], 'SSIM': []},\n",
        " '0.5': {'L1': [], 'PSNR': [], 'SSIM': []},\n",
        " '0.4': {'L1': [], 'PSNR': [], 'SSIM': []},\n",
        " '0.3': {'L1': [], 'PSNR': [], 'SSIM': []},\n",
        " '0.2': {'L1': [], 'PSNR': [], 'SSIM': []},\n",
        " '0.1': {'L1': [], 'PSNR': [], 'SSIM': []}}\n",
        "\"\"\"\"\""
      ],
      "metadata": {
        "id": "USuggIftiQU7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dp1MGLgCKjic"
      },
      "outputs": [],
      "source": [
        "\"\"\"\"\"\n",
        "metrics_dict = {'1.0': {'L1': [], 'PSNR': [], 'SSIM': []},\n",
        " '0.9': {'L1': [], 'PSNR': [], 'SSIM': []},\n",
        " '0.8': {'L1': [], 'PSNR': [], 'SSIM': []},\n",
        " '0.7': {'L1': [], 'PSNR': [], 'SSIM': []},\n",
        " '0.6': {'L1': [], 'PSNR': [], 'SSIM': []},\n",
        " '0.5': {'L1': [], 'PSNR': [], 'SSIM': []},\n",
        " '0.4': {'L1': [], 'PSNR': [], 'SSIM': []},\n",
        " '0.3': {'L1': [], 'PSNR': [], 'SSIM': []},\n",
        " '0.2': {'L1': [], 'PSNR': [], 'SSIM': []},\n",
        " '0.1': {'L1': [], 'PSNR': [], 'SSIM': []}}\n",
        "\"\"\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XIW-1Qa7tojD"
      },
      "outputs": [],
      "source": [
        "with open('/content/drive/MyDrive/Scriptie/json/metrics_30000_steps_v2.json') as json_file:\n",
        "    metrics_dict = json.load(json_file)\n",
        "\n",
        "with open('/content/drive/MyDrive/Scriptie/json/std_30000_steps.json') as json_file:\n",
        "    std_dict = json.load(json_file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yVqH7F5tRUNe"
      },
      "outputs": [],
      "source": [
        "def drop_rows(df, n_rows):\n",
        "  drop_rows = np.random.choice(df.index, n_rows, replace=False)\n",
        "  return df.drop(drop_rows)\n",
        "\n",
        "def tf_dataset(train_ds, val_ds):\n",
        "  #prepare training dataset\n",
        "  tf_train = train_ds.shuffle(train_ds.cardinality(), reshuffle_each_iteration=True)\n",
        "  tf_train = tf_train.map(load_images, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "  tf_train = tf_train.batch(BATCH_SIZE)\n",
        "  tf_train = tf_train.prefetch(tf.data.AUTOTUNE)\n",
        "  \n",
        "  #prepare validation dataset\n",
        "  tf_val = val_ds.map(load_images, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "  tf_val = tf_val.batch(BATCH_SIZE)\n",
        "  tf_val = tf_val.prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "  return tf_train, tf_val\n",
        "\n",
        "def reduce_data(train_df, val_df, reduce_percentage):\n",
        "  print(f\"Start reducing the dataset by {reduce_percentage*100}%\")\n",
        "  #determine number of rows to drop\n",
        "  n_drop_train = round(train_df.shape[0]*(1-reduce_percentage))\n",
        "  \n",
        "  #randomly drop rows\n",
        "  train_subset = drop_rows(train_df, n_drop_train)\n",
        "  #val_subset = drop_rows(val_df, n_drop_val)\n",
        "  print(f\"Dropped {n_drop_train} rows from the training set, training dataset now contains {train_subset.shape[0]} images\")\n",
        "  #print(f\"Dropped {n_drop_val} rows from the validation set\")\n",
        "\n",
        "  #make tensorflow datasets from the pandas dataframes\n",
        "  train_ds = tf.data.Dataset.from_tensor_slices(train_subset[\"Image\"])\n",
        "  val_ds = tf.data.Dataset.from_tensor_slices(val_df[\"Image\"])\n",
        "  train_ds, val_ds = tf_dataset(train_ds, val_ds)\n",
        "  print(f\"Tensorflow training dataset: {train_ds.cardinality()}. Tensorflow validation dataset: {val_ds.cardinality()}\")\n",
        "  \n",
        "  return train_ds, val_ds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5Jq4reMKaawK"
      },
      "outputs": [],
      "source": [
        "generator = Generator()\n",
        "discriminator = Discriminator()\n",
        "generator_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)\n",
        "discriminator_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o6CEE90GJZw7"
      },
      "outputs": [],
      "source": [
        "@tf.function\n",
        "def train_step(input_image, mask, target, epoch):\n",
        "  with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
        "    gen_output = generator([input_image], training=True) #generate image based on input\n",
        "    gen_output = gen_output*mask+ target*(1-mask) #combine generated patches with valid pixels from ground truth\n",
        "\n",
        "    disc_real_output = discriminator([input_image, target], training=True) #calculate discriminator loss for ground truth images\n",
        "    disc_generated_output = discriminator([input_image, gen_output], training=True) #calculate discriminator loss for predicted images\n",
        "\n",
        "    gen_total_loss, gen_gan_loss, gen_l1_loss = generator_loss(disc_generated_output, gen_output, target)\n",
        "    disc_loss = discriminator_loss(disc_real_output, disc_generated_output)\n",
        "\n",
        "  generator_gradients = gen_tape.gradient(gen_total_loss,\n",
        "                                          generator.trainable_variables)\n",
        "  discriminator_gradients = disc_tape.gradient(disc_loss,\n",
        "                                               discriminator.trainable_variables)\n",
        "\n",
        "  generator_optimizer.apply_gradients(zip(generator_gradients,\n",
        "                                          generator.trainable_variables))\n",
        "  discriminator_optimizer.apply_gradients(zip(discriminator_gradients,\n",
        "                                              discriminator.trainable_variables))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RuTYmIvFtZ6A"
      },
      "outputs": [],
      "source": [
        "proportion = 1.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uGQsImB4ekuw"
      },
      "outputs": [],
      "source": [
        "train_ds_subset, val_ds_subset = reduce_data(train_pd, val_pd, proportion)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y3c6iCTedwxu"
      },
      "outputs": [],
      "source": [
        "#train the model\n",
        "fit(train_ds_subset, val_ds_subset, 30000)\n",
        "\n",
        "print(\"Gathering metrics\")\n",
        "metrics_train = get_dataset_metrics(train_ds_subset)\n",
        "metrics_val = get_dataset_metrics(val_ds_subset)\n",
        "\n",
        "for key in metrics_dict[str(proportion)].keys():\n",
        "  metrics_dict[str(proportion)][key].append([str(metrics_train[key].mean()), str(metrics_val[key].mean())])\n",
        "  std_dict[str(proportion)][key].append([str(metrics_train[key].std()), str(metrics_val[key].std())])\n",
        "\n",
        "with open('/content/drive/MyDrive/Scriptie/json/metrics_30000_steps_v2.json', 'w') as j:\n",
        "  json.dump(metrics_dict, j, indent = 6)\n",
        "\n",
        "with open('/content/drive/MyDrive/Scriptie/json/std_30000_steps.json', 'w') as j:\n",
        "  json.dump(std_dict, j, indent = 6)\n",
        "\n",
        "display.clear_output(wait=True)\n",
        "print(len(metrics_dict[str(proportion)][\"L1\"]))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Plot"
      ],
      "metadata": {
        "id": "JJThqmgUvUtg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_dict(data):\n",
        "  # Create dictionaries for training and validation scores\n",
        "  train_dict = {}\n",
        "  val_dict = {}\n",
        "\n",
        "  for k, v in data.items():\n",
        "      for metric, scores in v.items():\n",
        "          if metric not in train_dict:\n",
        "              train_dict[metric] = []\n",
        "          if metric not in val_dict:\n",
        "              val_dict[metric] = []\n",
        "          train_score = sum([float(x[0]) for x in scores]) / len(scores)\n",
        "          val_score = sum([float(x[1]) for x in scores]) / len(scores)\n",
        "          if metric == \"L1\":\n",
        "            train_score = round(train_score)\n",
        "            val_score = round(val_score)\n",
        "          elif metric == \"PSNR\":\n",
        "            train_score = round(train_score, 2)\n",
        "            val_score = round(val_score, 2)\n",
        "          elif metric == \"SSIM\":\n",
        "            train_score = round(train_score, 4)\n",
        "            val_score = round(val_score, 4)\n",
        "          \n",
        "          train_dict[metric].append(train_score)\n",
        "          val_dict[metric].append(val_score)\n",
        "  \n",
        "  return train_dict, val_dict"
      ],
      "metadata": {
        "id": "bWyZOFM5ikh7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dict, val_dict = convert_dict(metrics_dict)\n",
        "train_dict_std, val_dict_std = convert_dict(std_dict)"
      ],
      "metadata": {
        "id": "kVewZ2Q0vXjP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "l1_val"
      ],
      "metadata": {
        "id": "-Y0TZBhPOxYl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "psnr_val"
      ],
      "metadata": {
        "id": "lX4cEu6sfYtA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ssim_val"
      ],
      "metadata": {
        "id": "JIcrMYjIfaEp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "std_l1_v"
      ],
      "metadata": {
        "id": "_WUgBbnDPlQq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.linspace(1.0, 0.1, 10)"
      ],
      "metadata": {
        "id": "_PCovjBDO-x0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "l1_train = train_dict[\"L1\"]\n",
        "l1_val = val_dict[\"L1\"]\n",
        "psnr_train = train_dict[\"PSNR\"]\n",
        "psnr_val = val_dict[\"PSNR\"]\n",
        "ssim_train = train_dict[\"SSIM\"]\n",
        "ssim_val = val_dict[\"SSIM\"]\n",
        "\n",
        "std_l1_t = train_dict_std[\"L1\"]\n",
        "std_l1_v = val_dict_std[\"L1\"]\n",
        "std_psnr_t = train_dict_std[\"PSNR\"]\n",
        "std_psnr_v = val_dict_std[\"PSNR\"]\n",
        "std_ssim_t = train_dict_std[\"SSIM\"]\n",
        "std_ssim_v = val_dict_std[\"SSIM\"]\n",
        "\n",
        "x = np.linspace(1.0, 0.1, 10)\n",
        "\n",
        "# Create subplots\n",
        "fig, axs = plt.subplots(nrows=1, ncols=3, figsize=(20, 5))\n",
        "\n",
        "# Plot data with error bars\n",
        "axs[0].errorbar(x, l1_train, yerr=std_l1_t, label='Train', solid_capstyle='projecting', capsize=5)\n",
        "axs[0].errorbar(x, l1_val, yerr=std_l1_v, label='Validation', solid_capstyle='projecting', capsize=5)\n",
        "\n",
        "axs[1].errorbar(x, psnr_train, yerr=std_psnr_t, label='Train', solid_capstyle='projecting', capsize=5)\n",
        "axs[1].errorbar(x, psnr_val, yerr=std_psnr_v, label='Validation', solid_capstyle='projecting', capsize=5)\n",
        "\n",
        "axs[2].errorbar(x, ssim_train, yerr=std_ssim_t, label='Train', solid_capstyle='projecting', capsize=5)\n",
        "axs[2].errorbar(x, ssim_val, yerr=std_ssim_v, label='Validation', solid_capstyle='projecting', capsize=5)\n",
        "\n",
        "# Set plot properties\n",
        "for i, ax in enumerate(axs):\n",
        "    ax.set_xlabel('Proportion of Training data')\n",
        "    ax.set_xticks(x)\n",
        "    if i == 0:\n",
        "      ax.set_ylabel('L1')\n",
        "    elif i == 1:\n",
        "      ax.set_ylabel('PSNR')\n",
        "    elif i == 2:\n",
        "      ax.set_ylabel('SSIM')\n",
        "    ax.legend()\n",
        "    ax.grid(True, alpha=0.3)\n",
        "\n",
        "# Show plot\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "EoxXYMwkkn_a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.image as mpimg"
      ],
      "metadata": {
        "id": "SnTkBvaeajzd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, axs = plt.subplots(nrows=4, ncols=3, figsize=(16, 12))\n",
        "input = \"/content/drive/MyDrive/Scriptie/Test_imgs/0.1/berlin/input.png\"\n",
        "gt = \"/content/drive/MyDrive/Scriptie/Test_imgs/0.1/berlin/target.png\"\n",
        "path = \"/content/drive/MyDrive/Scriptie/Test_imgs/\"\n",
        "im_path = \"/berlin/prediction.png\"\n",
        "images = np.array([input, gt] + [path+str((x+1)/10)+im_path for x in range(10)]).reshape(4,3)\n",
        "\n",
        "titles = np.array([\"Input\", \"Ground truth\"] + [str((x+1)/10) for x in range(10)]).reshape(4,3)\n",
        "\n",
        "for i, row in enumerate(axs):\n",
        "  for j, im in enumerate(row):\n",
        "    img = mpimg.imread(images[i][j])\n",
        "    im.imshow(img)\n",
        "    im.axis(\"off\")\n",
        "    im.set_title(titles[i][j])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "4d7_FhAdXiu6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ihx5GyU3PqwY"
      },
      "outputs": [],
      "source": [
        "path = \"/content/cityScapes/img/leftImg8bit/test\"\n",
        "test_fotos = [\"/berlin/berlin_000004_000019_leftImg8bit.png\",\n",
        "              \"/bielefeld/bielefeld_000000_020900_leftImg8bit.png\",\n",
        "              \"/bonn/bonn_000018_000019_leftImg8bit.png\",\n",
        "              \"/leverkusen/leverkusen_000045_000019_leftImg8bit.png\",\n",
        "              \"/mainz/mainz_000000_010417_leftImg8bit.png\",\n",
        "              \"/munich/munich_000242_000019_leftImg8bit.png\"]\n",
        "\n",
        "target_path = \"/content/drive/MyDrive/Scriptie/Test_imgs\" + \"/\" + str(proportion)\n",
        "cities = [\"berlin\", \"bielefeld\", \"bonn\", \"leverkusen\", \"mainz\", \"munich\"]\n",
        "names = [\"input\", \"target\", \"mask\", \"prediction\"]\n",
        "\n",
        "\n",
        "for idx, test_foto in enumerate(test_fotos):\n",
        "  path_to_im = path + test_foto\n",
        "  _, target, _, _, _ = load_images(path_to_im)\n",
        "  mask_path = os.path.join(\"/content/drive/MyDrive/Scriptie/Test_imgs/0.1\", cities[idx]) + \"/mask.png\"\n",
        "  mask = load(mask_path, 1)/255\n",
        "  inp = tf.where(tf.cast(mask, tf.bool), -1, target)\n",
        "  gen_output = generator([tf.expand_dims(inp, 0)], training=True)\n",
        "  gen_output = gen_output*mask+ target*(1-mask)\n",
        "  gen_output = np.squeeze(gen_output, 0)\n",
        "  ims = [inp, target, mask, gen_output]\n",
        "\n",
        "  for i in range(6):\n",
        "    for j in range(4):\n",
        "      target_str = os.path.join(target_path, cities[i], names[j]) + \".png\"\n",
        "      tf.keras.utils.save_img(target_str, ims[j])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for elements in train_ds_subset.take(1):\n",
        "  (masked_image, image, mask, image_file, locations) = elements"
      ],
      "metadata": {
        "id": "TWpvJUNDbuiG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "small_batch = val_ds_subset.take(1)"
      ],
      "metadata": {
        "id": "ImIcbfQemyhr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "get_dataset_metrics(small_batch)"
      ],
      "metadata": {
        "id": "noJpXqJEm8Me"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for masked_image, image, mask, image_file, locations in small_batch:\n",
        "  prediction = generator(masked_image, training=True) #estimated values for each of 35 classes\n",
        "  prediction = prediction * mask + image*(1-mask)\n",
        "\n",
        "  for i in range(prediction.shape[0]):\n",
        "    print(splitMaskMetrics_single(image[i], prediction[i], locations[i]))\n",
        "    fix,axs = plt.subplots(1,3, figsize=(15,15))\n",
        "    axs[0].imshow(masked_image[i]*0.5+0.5)\n",
        "    axs[1].imshow(image[i]*0.5+0.5)\n",
        "    axs[2].imshow(prediction[i]*0.5+0.5)\n",
        "    plt.axis(\"off\")\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "AtOg00ctoWoG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5b1uY5GPQr89"
      },
      "outputs": [],
      "source": [
        "metrics_train = get_dataset_metrics(train_ds_subset)\n",
        "metrics_val = get_dataset_metrics(val_ds_subset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WeEba-njzo6e"
      },
      "outputs": [],
      "source": [
        "print(metrics_train.mean())\n",
        "print(metrics_val.mean())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mNmCy87wY3WR"
      },
      "outputs": [],
      "source": [
        "print(list(metrics_dict.keys()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7vMEQd_xlvsq"
      },
      "outputs": [],
      "source": [
        "def convert_dtype(dtype, l1, l2):\n",
        "  return list(map(dtype, l1)), list(map(dtype, l2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ie0VhbGqfL4n"
      },
      "outputs": [],
      "source": [
        "l1_t, l1_v = list(zip(*metrics_dict[\"L1\"]))\n",
        "psnr_t, psnr_v = list(zip(*metrics_dict[\"PSNR\"]))\n",
        "ssim_t, ssim_v = list(zip(*metrics_dict[\"SSIM\"]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7tinVoRgl8R1"
      },
      "outputs": [],
      "source": [
        "l1_t, l1_v = convert_dtype(float, list(l1_t), list(l1_v))\n",
        "psnr_t, psnr_v = convert_dtype(float, list(psnr_t), list(psnr_v))\n",
        "ssim_t, ssim_v = convert_dtype(float, list(ssim_t), list(ssim_v))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s2szcJrRabgC"
      },
      "outputs": [],
      "source": [
        "def mean(data):\n",
        "  return sum(data)/len(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ABsR_eyJbc6t"
      },
      "outputs": [],
      "source": [
        "test = [\"1.0\", \"2.0\"]\n",
        "for i in test:\n",
        "  print(type(i), i)\n",
        "  i = float(i)\n",
        "  print(type(i), i)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XyAPVe8AXHV9"
      },
      "outputs": [],
      "source": [
        "def DataDict(dictionary, key):\n",
        "  train_list = []\n",
        "  val_list = []\n",
        "  x = list(metrics_dict.keys())\n",
        "  for i in x:\n",
        "    values = dictionary[i][key]\n",
        "    train_data, val_data = list(zip(*values))\n",
        "    train_data, val_data = list(map(float, train_data)), list(map(float, val_data))\n",
        "    train_list.append(mean(train_data))\n",
        "    val_list.append(mean(val_data))\n",
        "    \n",
        "  \n",
        "  return train_list, val_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NfBg5wg1m2vb"
      },
      "outputs": [],
      "source": [
        "def plot_data(train, val, title, x_axis, y_axis):\n",
        "  x = np.linspace(1.0, 0.1, 10, endpoint=True)\n",
        "  # plot lines\n",
        "  plt.plot(x, train, label = \"training data\")\n",
        "  plt.plot(x, val, label = \"validation data\")\n",
        "  plt.title(title)\n",
        "  plt.xlabel(x_axis)\n",
        "  plt.ylabel(y_axis)\n",
        "  plt.xticks(x)\n",
        "  plt.legend()\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0fpiwBYTnLQK"
      },
      "outputs": [],
      "source": [
        "title = \"L1 data decrease curve\"\n",
        "x_axis = \"Proportion of trainingset used\"\n",
        "y_axis = \"L1\"\n",
        "l1_t, l1_v = DataDict(metrics_dict, \"L1\")\n",
        "plot_data(l1_t, l1_v, title, x_axis, y_axis)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UZL9CsMX4dbb"
      },
      "outputs": [],
      "source": [
        "title = \"PSNR data decrease curve\"\n",
        "x_axis = \"Proportion of trainingset used\"\n",
        "y_axis = \"PSNR\"\n",
        "psnr_t, psnr_v = DataDict(metrics_dict, \"PSNR\")\n",
        "plot_data(psnr_t, psnr_v, title, x_axis, y_axis)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OmZXqgZF4dks"
      },
      "outputs": [],
      "source": [
        "title = \"SSIM data decrease curve\"\n",
        "x_axis = \"Proportion of trainingset used\"\n",
        "y_axis = \"SSIM\"\n",
        "ssim_t, ssim_v = DataDict(metrics_dict, \"SSIM\")\n",
        "plot_data(ssim_t, ssim_v, title, x_axis, y_axis)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Opv5KLCepYFU"
      },
      "outputs": [],
      "source": [
        "for i in tf_val.take(1):\n",
        "  masked_image, image, mask, image_file, locations = i\n",
        "plt.imshow(masked_image[0]*0.5+0.5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1bqXRKeVpgTf"
      },
      "outputs": [],
      "source": [
        "generate_images(generator, masked_image, image, mask)\n",
        "prediction = generator([masked_image], True)\n",
        "prediction = mask*prediction + (1-mask)*image\n",
        "data = splitMaskMetrics(image, prediction, locations)\n",
        "print(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pLcL1FnnhL5B"
      },
      "outputs": [],
      "source": [
        "data = splitMaskMetrics(image, prediction, locations)\n",
        "print(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eTyEy6WxQrdh"
      },
      "outputs": [],
      "source": [
        "print(tf.image.ssim(image, prediction, 255))\n",
        "print(tf.image.psnr(image, prediction, 255))\n",
        "print(tf.math.reduce_sum(tf.math.abs(image - prediction)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q60T7ejGIcKJ"
      },
      "outputs": [],
      "source": [
        "def fitSEMGAN(train_ds, test_ds, epochs):\n",
        "  masked_image_test, image_test, semantics_masked_test, semantics_test, mask_test, _, _ = next(iter(test_ds.take(1)))\n",
        "  start = time.time()\n",
        "  total_ims = tf.cast(train_ds.cardinality(), tf.float32)\n",
        "  total_ims_val = tf.cast(test_ds.cardinality(), tf.float32)\n",
        "\n",
        "  for epoch in range(epochs):\n",
        "    metrics_dict = {\"gen_total_loss\":0, \"gen_gan_loss\":0, \"gen_L1_loss\":0, \"disc_loss\":0}\n",
        "    \n",
        "    #semantics used for the example\n",
        "    semantics_predicted_test = gen_to_label(generator_semantics(semantics_masked_test, training=True)) # turn the generator output into labels\n",
        "    semantics_predicted_test = semantics_predicted_test*tf.cast(mask_test, tf.int32)+semantics_test*(1-tf.cast(mask_test, tf.int32)) # combine the prediction with the ground truth\n",
        "    semantics_sparse_test = label_to_sparse(semantics_predicted_test) # make a sparse matrix as input to the generator\n",
        "    generate_images(generatorSEMGAN, masked_image_test, image_test, semantics_predicted_test, semantics_sparse_test, mask_test)\n",
        "\n",
        "    print(\"Start training of epoch: \", epoch+1)\n",
        "    for step,(masked_image, image, semantics_masked, semantics, mask, _, _) in train_ds.enumerate():\n",
        "      semantics_predicted = gen_to_label(generator_semantics(semantics_masked, training=True)) # turn the generator output into labels\n",
        "      semantics_predicted = semantics_predicted * tf.cast(mask, tf.int32) + semantics *(1-tf.cast(mask, tf.int32)) # combine the prediction with the ground truth\n",
        "      semantics_predicted = label_to_sparse(semantics_predicted) # make a sparse matrix as input to the generator\n",
        "      gen_total_loss, gen_gan_loss, gen_L1_loss, disc_loss = train_epochSEMGAN(masked_image, image, semantics_predicted, mask)\n",
        "      metrics_list = (gen_total_loss, gen_gan_loss, gen_L1_loss, disc_loss)\n",
        "      \n",
        "      for i,(key,value) in enumerate(metrics_dict.items()):\n",
        "        metrics_dict[key] = value + metrics_list[i]\n",
        "      \n",
        "      if (step+1) % 50 == 0:\n",
        "        print('.', end='', flush=True)\n",
        "\n",
        "    with summary_writer_train.as_default():\n",
        "      tf.summary.scalar('gen_total_loss', metrics_dict[\"gen_total_loss\"]/total_ims, step=epoch)\n",
        "      tf.summary.scalar('gen_gan_loss', metrics_dict[\"gen_gan_loss\"]/total_ims, step=epoch)\n",
        "      tf.summary.scalar('gen_L1_loss', metrics_dict[\"gen_L1_loss\"]/total_ims, step=epoch)\n",
        "      tf.summary.scalar('disc_loss', metrics_dict[\"disc_loss\"]/total_ims, step=epoch)\n",
        "\n",
        "    fas\n",
        "    # Gather the metrics for the validation set\n",
        "    metrics_dict_val = {\"gen_total_loss\":0, \"gen_gan_loss\":0, \"gen_L1_loss\":0, \"disc_loss\":0}\n",
        "    print(\"Gathering validation set metrics...\")\n",
        "    for step,(masked_image, image, semantics_masked, semantics, mask, _, _) in test_ds.enumerate():\n",
        "      semantics_predicted = gen_to_label(generator_semantics(semantics_masked, training=True))\n",
        "      semantics_predicted = semantics_predicted * tf.cast(mask, tf.int32) + semantics *(1-tf.cast(mask, tf.int32))\n",
        "      semantics_predicted = label_to_sparse(semantics_predicted)\n",
        "      gen_total_loss, gen_gan_loss, gen_L1_loss, disc_loss = getValAccLossSEMGAN(masked_image, image, semantics_predicted, mask)\n",
        "      metrics_list_val = (gen_total_loss, gen_gan_loss, gen_L1_loss, disc_loss)\n",
        "        \n",
        "      for i,(key,value) in enumerate(metrics_dict_val.items()):\n",
        "        metrics_dict_val[key] = value + metrics_list_val[i]\n",
        "    \n",
        "    with summary_writer_val.as_default():\n",
        "      tf.summary.scalar('gen_total_loss', metrics_dict_val[\"gen_total_loss\"]/total_ims_val, step=epoch)\n",
        "      tf.summary.scalar('gen_gan_loss', metrics_dict_val[\"gen_gan_loss\"]/total_ims_val, step=epoch)\n",
        "      tf.summary.scalar('gen_L1_loss', metrics_dict_val[\"gen_L1_loss\"]/total_ims_val, step=epoch)\n",
        "      tf.summary.scalar('disc_loss', metrics_dict_val[\"disc_loss\"]/total_ims_val, step=epoch)\n",
        "\n",
        "    display.clear_output(wait=True)\n",
        "    print(f'Time taken for 1 epoch: {time.time()-start:.2f} sec\\n')\n",
        "    start = time.time()\n",
        "\n",
        "    # Save (checkpoint) the model every 5 epochs\n",
        "    #if epoch % 10 == 0 & epoch !=0: \n",
        "    #  checkpoint.save(file_prefix=checkpoint_prefix)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JxdoiTytWAjm"
      },
      "source": [
        "# Plot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PjahO8A35lH0"
      },
      "outputs": [],
      "source": [
        "checkpoint.restore(\"/content/drive/MyDrive/Scriptie/ckpt/P2P/TransposeConv/ckpt-1\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9Zp7l9Xd6OH0"
      },
      "outputs": [],
      "source": [
        "example_input, example_target, mask_test, path, locations = next(iter(tf_val.take(1)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mKUE2m1y6UFM"
      },
      "outputs": [],
      "source": [
        "plt.imshow(example_target[0]*0.5+0.5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z0eUxMAL6Xgs"
      },
      "outputs": [],
      "source": [
        "prediction = generator(example_input, True)\n",
        "prediction = mask_test * prediction + example_target * (1-mask_test)\n",
        "plt.imshow(prediction[0]*0.5+0.5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4zio7WcZ6lxf"
      },
      "outputs": [],
      "source": [
        "splitMaskMetrics(example_target, prediction, locations)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4KbmSmdC7HHb"
      },
      "outputs": [],
      "source": [
        "metrics(example_target, prediction)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import glob"
      ],
      "metadata": {
        "id": "jfFXxAQv4O7B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for root, dirs, files in os.walk(\"/content/drive/MyDrive/Scriptie/Test_imgs\", topdown = True):\n",
        "   for name in files:\n",
        "      print(os.path.join(root, name))"
      ],
      "metadata": {
        "id": "2wV7PKzU19hS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GYdVZRD22xH2"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "2Qcr2R4c9DMY",
        "5ULcR49yeeAR",
        "Up9HfI1T9iUP",
        "gKZPywWbcFcY",
        "oBxAxyEOnZlc",
        "IB5iqOfSncW8",
        "6wkL-E7EZ7mM"
      ],
      "provenance": [],
      "machine_shape": "hm"
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}